{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Antagonist to train a symptom detection model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ToDo\n",
    "\n",
    "- [OK] Change threshold to detect symptoms\n",
    "- [OK] Use training data from a metric in addition to current data\n",
    "- [OK] Remove known anomalies from training data \n",
    "- Generate list of network incident aggregating the symptoms\n",
    "- Use API from the plugin to get and store labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "# Python\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "# Numpy\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset preparation\n",
    "\n",
    "Note: the dataset needs to be downloaded using the script `download_SMD_dataset.sh` in the `scripts/antagonist-ml` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import SMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SMD(dataset_folder=r\"D:\\antagonist\\data\\ServerMachineDataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_train, _ = db.read_dataset(group_name=\"Group 1\", train=True, retrieve_labels=True)\n",
    "dataframes, files = db.read_dataset(group_name=\"Group 1\", train=False, retrieve_labels=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_idx = 0\n",
    "df,service_id = dataframes[service_idx], files[service_idx]\n",
    "df,labels = df[df.columns[:-2].tolist()+['timestamp']], df[['label']]\n",
    "df_train = dataframes_train[service_idx]\n",
    "df_train = df_train[df_train.columns[:-1].tolist()+['timestamp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_incidents = db.get_interpretation_labels(service_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from auto_encoder import Vanilla_AE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = df.shape[1] - 1\n",
    "layer_sizes = [8, 4, 2]\n",
    "lr = 0.005\n",
    "batch_size = 32\n",
    "epochs = 40\n",
    "validation_split = 0.2\n",
    "early_stopping = True\n",
    "patience = 3\n",
    "Q = 0.99  # residual cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df: pd.DataFrame):\n",
    "    ae = Vanilla_AE(n_inputs=n_inputs, layer_sizes=layer_sizes)\n",
    "\n",
    "    # Get data but the timestamp\n",
    "    X_train = df.values[:, :-1]\n",
    "\n",
    "    # scaler init and fitting\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "    # model fitting\n",
    "    ae.fit(\n",
    "        X_train_scaled,\n",
    "        early_stopping=early_stopping,\n",
    "        validation_split=validation_split,\n",
    "        epochs=epochs,\n",
    "        lr=lr,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0,\n",
    "        shuffle=True,\n",
    "        patience=patience,\n",
    "        delta=0.001,\n",
    "    )\n",
    "\n",
    "    # results predicting\n",
    "    residuals_train = (\n",
    "        pd.DataFrame(X_train_scaled - ae.predict(X_train_scaled)).abs()\n",
    "    )\n",
    "    threshold = residuals_train.quantile(Q,axis=0) * 5 / 2\n",
    "\n",
    "    return scaler, ae, threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_consecutive_true_np(arr):\n",
    "    result = []\n",
    "    for i in range(arr.shape[1]):\n",
    "        s = arr[:, i]\n",
    "        m = np.r_[False, s, False]\n",
    "        idx = np.flatnonzero(m[1:] != m[:-1])\n",
    "        result.append(list(zip(idx[::2], idx[1::2])) )\n",
    "    return result\n",
    "\n",
    "def predict(df, scaler, ae, threshold, aggregate=False ):\n",
    "\n",
    "    X_hat = scaler.transform(df.values[:,:-1])\n",
    "    residuals_full_df = X_hat - ae.predict(X_hat)\n",
    "    residuals_full_df = pd.DataFrame(residuals_full_df).abs()\n",
    "    \n",
    "    symptoms = (residuals_full_df > threshold).values\n",
    "\n",
    "    return symptoms.any(axis=1) if aggregate else symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(df, labels,  scaler, ae, threshold ):\n",
    "\n",
    "    X_hat = scaler.transform(df.values[:,:-1])\n",
    "    residuals_full_df = X_hat - ae.predict(X_hat)\n",
    "    residuals_full_df = pd.DataFrame(residuals_full_df).abs()\n",
    "    residuals_full_df['outlier'] = (residuals_full_df > threshold).any(axis=1).astype(int).values\n",
    "\n",
    "    return f1_score(labels['label'].values,residuals_full_df['outlier'].values, average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterative process simulation\n",
    "\n",
    "Every day the model is retrained with the new data and new labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.datetime.fromtimestamp(df['timestamp'].astype('int64').min()/10**9)\n",
    "end_date = datetime.datetime.fromtimestamp(df['timestamp'].dt.ceil('D').astype('int64').max()/10**9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 8\n"
     ]
    }
   ],
   "source": [
    "scaler, ae, threshold = None, None, None\n",
    "previous_day = None\n",
    "\n",
    "symptoms_predictions = dict()\n",
    "\n",
    "for current_day in pd.date_range(start=start_date, end=end_date, freq=\"D\"):\n",
    "    current_day = datetime.datetime.fromtimestamp(current_day.timestamp())\n",
    "    df_today = df.loc[df[\"timestamp\"] < current_day.ctime()]\n",
    "\n",
    "    if df_today.shape[0] == 0:\n",
    "        # first day\n",
    "        continue\n",
    "\n",
    "    # Predict symptoms for the current day\n",
    "    if scaler is not None and previous_day is not None:\n",
    "        df_pred = df.loc[\n",
    "            (df[\"timestamp\"] >= previous_day.ctime())\n",
    "            & (df[\"timestamp\"] < current_day.ctime())\n",
    "        ]\n",
    "        y_pred = predict(df_pred, scaler, ae, threshold, aggregate=False)\n",
    "\n",
    "        intervals = find_consecutive_true_np(y_pred)\n",
    "        for metric_id, symptoms in enumerate(intervals):\n",
    "            if len(symptoms) > 0:\n",
    "                symptoms_predictions[current_day] = defaultdict(list)\n",
    "            for symp in symptoms:\n",
    "                symptoms_predictions[current_day][metric_id].append(\n",
    "                    [\n",
    "                        df_pred[\"timestamp\"].iloc[symp[0]].timestamp(),\n",
    "                        df_pred[\"timestamp\"].iloc[symp[1] - 1].timestamp(),\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "        break\n",
    "\n",
    "    # Retrain the model on the available data removing anomalies (simulating human validation)\n",
    "    mask_train = labels[: df_today.shape[0]][\"label\"] == 0\n",
    "    df_today = pd.concat([df_train, df_today[mask_train]], ignore_index=True)\n",
    "    scaler, ae, threshold = train_model(df_today)\n",
    "    previous_day = current_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.3014\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on the overall test set\n",
    "f1 = eval_model(df, labels, scaler, ae, threshold)\n",
    "print(f\"F1 score: {round(f1,4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-03\n"
     ]
    }
   ],
   "source": [
    "# Aggregate symptoms in network incidents according to the OR rule\n",
    "incidents_predictions = {}\n",
    "for model_date, symptoms in symptoms_predictions.items():\n",
    "    print(model_date.strftime('%Y-%m-%d'))\n",
    "\n",
    "    # aggregate overlapping symptoms coming from different metrics\n",
    "    day_symptoms = [\n",
    "        (metric_id, symptom[0], symptom[1]) for metric_id, symptoms_list in symptoms.items() for symptom in symptoms_list \n",
    "    ]\n",
    "\n",
    "    # sort by starting timestamp\n",
    "    day_symptoms.sort(key=lambda x: x[1])\n",
    "\n",
    "    if len(day_symptoms) == 0:\n",
    "        continue\n",
    "\n",
    "\n",
    "    # create a list of incident in the form [(start_timestamp, end_timestamp, [symptom1, symptom2]),...]\n",
    "    start = day_symptoms[0][1] \n",
    "    end = day_symptoms[0][2]\n",
    "    network_incidents = [(start, end, [day_symptoms[0]])]\n",
    "    for symptom in day_symptoms[1:]:\n",
    "        # if overlapping add to the current incident, new incident otherwise\n",
    "        if symptom[1] <= end:\n",
    "            network_incidents[-1][2].append(symptom)\n",
    "            end = max(end, symptom[2])\n",
    "            network_incidents[-1][1] = end\n",
    "        else:\n",
    "            start = symptom[1]\n",
    "            end = symptom[2]\n",
    "            network_incidents.append((start, end, [symptom]))\n",
    "\n",
    "    incidents_predictions[model_date] = network_incidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_anomalies = []\n",
    "symptoms = []\n",
    "symptoms_to_network_anomalies = []\n",
    "\n",
    "for model_date, network_incidents in incidents_predictions.items():\n",
    "    for network_incident in network_incidents:\n",
    "        ni_uuid=str(uuid.uuid4())\n",
    "        network_anomalies.append({\n",
    "            'author': {\n",
    "                            'author_type': 'algorithm',\n",
    "                            'name':  \"ae_continual_learning\",\n",
    "                            'version': int(model_date.timestamp())\n",
    "                        },\n",
    "            'description': model_date.strftime(\"%Y-%m-%d\"),\n",
    "            'start': network_incident[0],\n",
    "            'end': network_incident[1],\n",
    "            'id': ni_uuid,\n",
    "            'state': 'potential',\n",
    "            'version': 1\n",
    "        })\n",
    "\n",
    "        for symptom in network_incident[2]:\n",
    "            symptom_uuid=str(uuid.uuid4())\n",
    "            symptoms.append(\n",
    "                {\n",
    "                    \"confidence-score\": 1.0,\n",
    "                    \"description\": \"Automatic generated symptom\",\n",
    "                    \"start-time\": datetime.datetime.fromtimestamp(symptom[1]).strftime(\"%Y-%m-%dT%H:%M:%S\"),\n",
    "                    \"end-time\":  datetime.datetime.fromtimestamp(symptom[2]).strftime(\"%Y-%m-%dT%H:%M:%S\"),\n",
    "                    \"event-id\": str(uuid.uuid4()),\n",
    "                    \"id\": symptom_uuid,\n",
    "                    \"source-name\": f\"ae_{model_date.strftime('%Y-%m-%d')}\",\n",
    "                    \"source-type\": \"algorithm\",\n",
    "                    \"tags\": {\n",
    "                        \"machine\":service_id,\n",
    "                        \"metric_id\":symptom[0]\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "\n",
    "            symptoms_to_network_anomalies.append({\n",
    "                \"symptom-id\": symptom_uuid,\n",
    "                \"incident-id\": ni_uuid\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'author': {'author_type': 'algorithm',\n",
       "   'name': 'ae_continual_learning',\n",
       "   'version': 1578009600},\n",
       "  'description': '2020-01-03',\n",
       "  'start': 1577925900.0,\n",
       "  'end': 1577925960.0,\n",
       "  'id': '1fe81d3f-c082-43aa-8012-9793d1f86ba5',\n",
       "  'state': 'potential',\n",
       "  'version': 1},\n",
       " {'author': {'author_type': 'algorithm',\n",
       "   'name': 'ae_continual_learning',\n",
       "   'version': 1578009600},\n",
       "  'description': '2020-01-03',\n",
       "  'start': 1577926200.0,\n",
       "  'end': 1577926200.0,\n",
       "  'id': 'f70debdc-c346-4cf6-9b60-3666aa26ad47',\n",
       "  'state': 'potential',\n",
       "  'version': 1},\n",
       " {'author': {'author_type': 'algorithm',\n",
       "   'name': 'ae_continual_learning',\n",
       "   'version': 1578009600},\n",
       "  'description': '2020-01-03',\n",
       "  'start': 1577928240.0,\n",
       "  'end': 1577928240.0,\n",
       "  'id': 'aa42090f-fb91-41fb-8e07-3ae219c0bf0b',\n",
       "  'state': 'potential',\n",
       "  'version': 1},\n",
       " {'author': {'author_type': 'algorithm',\n",
       "   'name': 'ae_continual_learning',\n",
       "   'version': 1578009600},\n",
       "  'description': '2020-01-03',\n",
       "  'start': 1577938440.0,\n",
       "  'end': 1577938440.0,\n",
       "  'id': '4f7de320-3bb3-4414-9820-76e527fc50dd',\n",
       "  'state': 'potential',\n",
       "  'version': 1},\n",
       " {'author': {'author_type': 'algorithm',\n",
       "   'name': 'ae_continual_learning',\n",
       "   'version': 1578009600},\n",
       "  'description': '2020-01-03',\n",
       "  'start': 1577938560.0,\n",
       "  'end': 1577938560.0,\n",
       "  'id': '21005306-4907-470e-a48d-8cde30dfa9e2',\n",
       "  'state': 'potential',\n",
       "  'version': 1}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'confidence-score': 1.0,\n",
       "  'description': 'Automatic generated symptom',\n",
       "  'start-time': '2020-01-02T00:45:00',\n",
       "  'end-time': '2020-01-02T00:46:00',\n",
       "  'event-id': 'fc1501be-066f-4dbe-94ac-fc68632b4b58',\n",
       "  'id': '45a52fde-f646-4df1-9f4b-a5624f0c8bd2',\n",
       "  'source-name': 'ae_2020-01-03',\n",
       "  'source-type': 'algorithm',\n",
       "  'tags': {'machine': 'machine-1-1.txt', 'metric_id': 33}},\n",
       " {'confidence-score': 1.0,\n",
       "  'description': 'Automatic generated symptom',\n",
       "  'start-time': '2020-01-02T00:50:00',\n",
       "  'end-time': '2020-01-02T00:50:00',\n",
       "  'event-id': 'aaf5d962-378c-45ab-bf75-891ddc64ba75',\n",
       "  'id': '7f629060-4941-4df8-9f24-ede16173ec7d',\n",
       "  'source-name': 'ae_2020-01-03',\n",
       "  'source-type': 'algorithm',\n",
       "  'tags': {'machine': 'machine-1-1.txt', 'metric_id': 33}},\n",
       " {'confidence-score': 1.0,\n",
       "  'description': 'Automatic generated symptom',\n",
       "  'start-time': '2020-01-02T01:24:00',\n",
       "  'end-time': '2020-01-02T01:24:00',\n",
       "  'event-id': '79cce49b-a022-46d2-b018-868782bd4821',\n",
       "  'id': '2003a711-74e2-4619-9944-f05b6a3b9132',\n",
       "  'source-name': 'ae_2020-01-03',\n",
       "  'source-type': 'algorithm',\n",
       "  'tags': {'machine': 'machine-1-1.txt', 'metric_id': 33}},\n",
       " {'confidence-score': 1.0,\n",
       "  'description': 'Automatic generated symptom',\n",
       "  'start-time': '2020-01-02T04:14:00',\n",
       "  'end-time': '2020-01-02T04:14:00',\n",
       "  'event-id': '561d6ba9-19f6-4c6c-81f3-e7e4a6761dde',\n",
       "  'id': 'dd5a2084-c76c-472c-aac8-319f6ff5a4fe',\n",
       "  'source-name': 'ae_2020-01-03',\n",
       "  'source-type': 'algorithm',\n",
       "  'tags': {'machine': 'machine-1-1.txt', 'metric_id': 33}},\n",
       " {'confidence-score': 1.0,\n",
       "  'description': 'Automatic generated symptom',\n",
       "  'start-time': '2020-01-02T04:16:00',\n",
       "  'end-time': '2020-01-02T04:16:00',\n",
       "  'event-id': 'e8ce8a99-a908-4859-a93a-7ccb21fc288d',\n",
       "  'id': 'c48d4323-79ae-42cd-a64d-c8598cfb12f0',\n",
       "  'source-name': 'ae_2020-01-03',\n",
       "  'source-type': 'algorithm',\n",
       "  'tags': {'machine': 'machine-1-1.txt', 'metric_id': 33}}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#    \"action\": \"Reachability\",\n",
    "#    \"cause\": \"Peer Down\",\n",
    "#    \"pattern\": \"drop\",\n",
    "#    \"plane\": \"control\",\n",
    "#    \"reason\": \"Withdraw\",\n",
    "symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'symptom-id': '45a52fde-f646-4df1-9f4b-a5624f0c8bd2',\n",
       "  'incident-id': '1fe81d3f-c082-43aa-8012-9793d1f86ba5'},\n",
       " {'symptom-id': '7f629060-4941-4df8-9f24-ede16173ec7d',\n",
       "  'incident-id': 'f70debdc-c346-4cf6-9b60-3666aa26ad47'},\n",
       " {'symptom-id': '2003a711-74e2-4619-9944-f05b6a3b9132',\n",
       "  'incident-id': 'aa42090f-fb91-41fb-8e07-3ae219c0bf0b'},\n",
       " {'symptom-id': 'dd5a2084-c76c-472c-aac8-319f6ff5a4fe',\n",
       "  'incident-id': '4f7de320-3bb3-4414-9820-76e527fc50dd'},\n",
       " {'symptom-id': 'c48d4323-79ae-42cd-a64d-c8598cfb12f0',\n",
       "  'incident-id': '21005306-4907-470e-a48d-8cde30dfa9e2'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symptoms_to_network_anomalies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
