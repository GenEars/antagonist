{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Antagonist to train a symptom detection model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reproducibility\n",
    "\n",
    "Set seeds to ensure reproducible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "# Python\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "# Numpy\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset preparation\n",
    "\n",
    "Note: the dataset needs to be downloaded using the script `download_SMD_dataset.sh` in the `scripts/antagonist-ml` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "from utils import SMDInfluxDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the antagonist_ml methods\n",
    "import sys \n",
    "sys.path.append(\"..\")\n",
    "from antagonist_ml.service import get_network_symptoms_labels, store_network_anomalies_labels, store_network_symptom_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = \"Group-1\"\n",
    "machine_id = 'machine-1-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data in the last year to be sure to read all the dataset\n",
    "end = datetime.datetime.now()\n",
    "start = end - datetime.timedelta(days=365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SMDInfluxDB()\n",
    "dataframes, machines = db.read_dataset(\n",
    "    start_date=start,\n",
    "    end_date=end,\n",
    "    machine_name=machine_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataframes[0]\n",
    "df = df[df.columns[1:].tolist()+['timestamp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = get_network_symptoms_labels(\n",
    "    \"localhost:5001\",\n",
    "    source_type=\"human\",\n",
    "    start_timestamp=start.timestamp(),\n",
    "    end_timestamp=end.timestamp(),\n",
    "    tags={\"machine\": machine_id},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label = np.zeros(df.shape[0])\n",
    "\n",
    "for symptom in ground_truth:\n",
    "    y_label[(df[\"timestamp\"] >= pd.Timestamp(symptom['start-time'], unit=\"s\", tz=\"UTC\"))&(df[\"timestamp\"] <= pd.Timestamp(symptom['end-time'], unit=\"s\", tz=\"UTC\"))] = 1\n",
    "\n",
    "df_labels = pd.DataFrame(y_label, columns=[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ML Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from ml_ad import AENetworkAnomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter up to current day to simulate the predition on the next one\n",
    "current_day = df['timestamp'].min() + datetime.timedelta(days=12)\n",
    "next_day = current_day + datetime.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models folder\n",
    "data_folder = r\"..\\..\\..\\data\"\n",
    "models_folder = os.path.join(data_folder,'models')\n",
    "os.makedirs(models_folder,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'ae_model_{(current_day).strftime(\"%Y%m%d\")}'\n",
    "model_folder = os.path.join(models_folder, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(model_folder):\n",
    "    # Load the model if it exist\n",
    "    ml_model = AENetworkAnomaly.load(model_folder)\n",
    "else:\n",
    "    # Create new model \n",
    "    ml_model = AENetworkAnomaly(n_inputs=df.shape[1]-1)\n",
    "\n",
    "    # Get data up to current day (training set)\n",
    "    df_today = df.loc[df[\"timestamp\"] < current_day.ctime()]\n",
    "\n",
    "    # Train the model\n",
    "    X_train = df_today.drop('timestamp',axis=1).values\n",
    "    ml_model.fit(X_train)\n",
    "\n",
    "    # Cache the trained model\n",
    "    ml_model.store(model_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use model for detection\n",
    "\n",
    "Predict anomalies on the current day data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df.loc[\n",
    "    (df[\"timestamp\"] >= current_day.ctime())\n",
    "    & (df[\"timestamp\"] < next_day.ctime())\n",
    "]\n",
    "\n",
    "X_pred = df_pred.drop('timestamp',axis=1).values\n",
    "y_pred = ml_model.predict(X_pred, aggregate=False)\n",
    "model_predictions = ml_model.parse_predictions(df_pred, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to objects\n",
    "\n",
    "In the following code overlapping symptoms are aggregated into incidents. The code iterates over the sorted list of symptoms and groups them into incidents based on their overlapping time ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate overlapping symptoms coming from different metrics\n",
    "day_symptoms = [\n",
    "    (metric_id, symptom[0], symptom[1]) for metric_id, symptoms_list in model_predictions.items() for symptom in symptoms_list \n",
    "]\n",
    "\n",
    "# sort by starting timestamp\n",
    "day_symptoms.sort(key=lambda x: x[1])\n",
    "\n",
    "if len(day_symptoms) > 0:\n",
    "    # create a list of incident in the form [(start_timestamp, end_timestamp, [symptom1, symptom2]),...]\n",
    "    start = day_symptoms[0][1] \n",
    "    end = day_symptoms[0][2]\n",
    "    network_incidents = [[start, end, [day_symptoms[0]]]]\n",
    "    for symptom in day_symptoms[1:]:\n",
    "        # if overlapping add to the current incident, new incident otherwise\n",
    "        if symptom[1] <= end:\n",
    "            network_incidents[-1][2].append(symptom)\n",
    "            end = max(end, symptom[2])\n",
    "            network_incidents[-1][1] = end\n",
    "        else:\n",
    "            start = symptom[1]\n",
    "            end = symptom[2]\n",
    "            network_incidents.append([start, end, [symptom]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store into antagonist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for network_incident in network_incidents:\n",
    "\n",
    "    # Create network incident label\n",
    "    ni_uuid = store_network_anomalies_labels(\n",
    "        antagonist_host='localhost:5001',\n",
    "        author_name=model_name,\n",
    "        author_type=\"algorithm\",\n",
    "        author_version=1,\n",
    "        description=f'Detected Network Anomaly on {machine_id} - {datetime.datetime.fromtimestamp(network_incident[0]).strftime(\"%Y-%m-%d at %H\")}',\n",
    "        state=\"incident-potential\",\n",
    "        version=1,\n",
    "    )\n",
    "\n",
    "    # Create network symptoms labels and link with the network incident\n",
    "    for symptom in network_incident[2]:\n",
    "        store_network_symptom_labels(    \n",
    "            antagonist_host='localhost:5001',\n",
    "            author_name=model_name,\n",
    "            author_type=\"algorithm\",\n",
    "            author_version=1,\n",
    "            confidence=1.0,\n",
    "            concern_score=0.9,\n",
    "            description=f\"Detected Symptom on {db.get_metric_names()[symptom[0]]} of {machine_id}\",\n",
    "            start=symptom[1],\n",
    "            end=symptom[2],\n",
    "            version=1,\n",
    "            tags={\"machine\": machine_id, \"metric\": db.get_metric_names()[symptom[0]], \"group\": group},\n",
    "            network_anomaly_uuid=ni_uuid,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for network_incident in network_incidents:\n",
    "    for symptom in network_incident[2]:\n",
    "        print(f\"Detected Symptom on {db.get_metric_names()[symptom[0]]} of {machine_id}\")\n",
    "        print(datetime.datetime.fromtimestamp(symptom[1]))\n",
    "        print(datetime.datetime.fromtimestamp(symptom[2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
