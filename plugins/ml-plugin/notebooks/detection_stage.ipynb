{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Antagonist to train a symptom detection model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reproducibility\n",
    "\n",
    "Set seeds to ensure reproducible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "# Python\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "# Numpy\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset preparation\n",
    "\n",
    "Note: the dataset needs to loaded into influxDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "from utils import SMDInfluxDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the antagonist_ml methods\n",
    "import sys \n",
    "sys.path.append(\"..\")\n",
    "from antagonist_ml.service import get_network_symptoms_labels, store_network_anomalies_labels, store_network_symptom_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = \"Group-1\"\n",
    "machine_id = 'machine-1-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data in the last year to be sure to read all the dataset\n",
    "end = datetime.datetime.now()\n",
    "start = end - datetime.timedelta(days=365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SMDInfluxDB()\n",
    "dataframes, machines = db.read_dataset(\n",
    "    start_date=start,\n",
    "    end_date=end,\n",
    "    machine_name=machine_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataframes[0]\n",
    "df = df[df.columns[1:].tolist()+['timestamp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = get_network_symptoms_labels(\n",
    "    \"localhost:5001\",\n",
    "    source_type=\"human\",\n",
    "    start_timestamp=start.timestamp(),\n",
    "    end_timestamp=end.timestamp(),\n",
    "    tags={\"machine\": machine_id},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label = np.zeros(df.shape[0])\n",
    "\n",
    "for symptom in ground_truth:\n",
    "    y_label[(df[\"timestamp\"] >= pd.Timestamp(symptom['start-time'], unit=\"s\", tz=\"UTC\"))&(df[\"timestamp\"] <= pd.Timestamp(symptom['end-time'], unit=\"s\", tz=\"UTC\"))] = 1\n",
    "\n",
    "df_labels = pd.DataFrame(y_label, columns=[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ML Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from ml_ad import AENetworkAnomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter up to current day to simulate the predition on the next one\n",
    "current_day = df['timestamp'].min() + datetime.timedelta(days=12)\n",
    "next_day = current_day + datetime.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models folder\n",
    "data_folder = r\"..\\..\\..\\data\"\n",
    "models_folder = os.path.join(data_folder,'models')\n",
    "os.makedirs(models_folder,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'ae_model_{(current_day).strftime(\"%Y%m%d\")}'\n",
    "model_folder = os.path.join(models_folder, 'ae_model_champion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(model_folder):\n",
    "    # Load the model if it exist\n",
    "    ml_model = AENetworkAnomaly.load(model_folder)\n",
    "else:\n",
    "    # Create new model \n",
    "    ml_model = AENetworkAnomaly(n_inputs=df.shape[1]-1)\n",
    "\n",
    "    # Get data up to current day (training set)\n",
    "    df_today = df.loc[df[\"timestamp\"] < current_day.ctime()]\n",
    "\n",
    "    # Train the model\n",
    "    X_train = df_today.drop('timestamp',axis=1).values\n",
    "    ml_model.fit(X_train)\n",
    "\n",
    "    # Cache the trained model\n",
    "    ml_model.store(model_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use model for detection\n",
    "\n",
    "Predict anomalies on the current day data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df.loc[\n",
    "    (df[\"timestamp\"] >= current_day.ctime())\n",
    "    & (df[\"timestamp\"] < next_day.ctime())\n",
    "]\n",
    "\n",
    "X_pred = df_pred.drop('timestamp',axis=1).values\n",
    "y_pred = ml_model.predict(X_pred, aggregate=False)\n",
    "model_predictions = ml_model.parse_predictions(df_pred, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to objects\n",
    "\n",
    "In the following code overlapping symptoms are aggregated into incidents. The code iterates over the sorted list of symptoms and groups them into incidents based on their overlapping time ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate overlapping symptoms coming from different metrics\n",
    "day_symptoms = [\n",
    "    (metric_id, symptom[0], symptom[1]) for metric_id, symptoms_list in model_predictions.items() for symptom in symptoms_list \n",
    "]\n",
    "\n",
    "# sort by starting timestamp\n",
    "day_symptoms.sort(key=lambda x: x[1])\n",
    "\n",
    "if len(day_symptoms) > 0:\n",
    "    # create a list of incident in the form [(start_timestamp, end_timestamp, [symptom1, symptom2]),...]\n",
    "    start = day_symptoms[0][1] \n",
    "    end = day_symptoms[0][2]\n",
    "    network_incidents = [[start, end, [day_symptoms[0]]]]\n",
    "    for symptom in day_symptoms[1:]:\n",
    "        # if overlapping add to the current incident, new incident otherwise\n",
    "        if symptom[1] <= end:\n",
    "            network_incidents[-1][2].append(symptom)\n",
    "            end = max(end, symptom[2])\n",
    "            network_incidents[-1][1] = end\n",
    "        else:\n",
    "            start = symptom[1]\n",
    "            end = symptom[2]\n",
    "            network_incidents.append([start, end, [symptom]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store into antagonist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for network_incident in network_incidents:\n",
    "\n",
    "    # Create network incident label\n",
    "    ni_uuid = store_network_anomalies_labels(\n",
    "        antagonist_host='localhost:5001',\n",
    "        author_name=model_name,\n",
    "        author_type=\"algorithm\",\n",
    "        author_version=1,\n",
    "        description=f'Detected Network Anomaly on {machine_id} - {datetime.datetime.fromtimestamp(network_incident[0]).strftime(\"%Y-%m-%d at %H\")}',\n",
    "        state=\"incident-potential\",\n",
    "        version=1,\n",
    "    )\n",
    "\n",
    "    # Create network symptoms labels and link with the network incident\n",
    "    for symptom in network_incident[2]:\n",
    "        store_network_symptom_labels(    \n",
    "            antagonist_host='localhost:5001',\n",
    "            author_name=model_name,\n",
    "            author_type=\"algorithm\",\n",
    "            author_version=1,\n",
    "            confidence=1.0,\n",
    "            concern_score=0.9,\n",
    "            description=f\"Detected Symptom on {db.get_metric_names()[symptom[0]]} of {machine_id}\",\n",
    "            start=symptom[1],\n",
    "            end=symptom[2],\n",
    "            version=1,\n",
    "            tags={\"machine\": machine_id, \"metric\": db.get_metric_names()[symptom[0]], \"group\": group},\n",
    "            network_anomaly_uuid=ni_uuid,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Symptom on mem_u of machine-1-1\n",
      "2024-06-01 10:14:43\n",
      "2024-06-01 10:15:43\n",
      "Detected Symptom on disk_rb of machine-1-1\n",
      "2024-06-01 10:14:43\n",
      "2024-06-01 10:15:43\n",
      "Detected Symptom on mem_shmem of machine-1-1\n",
      "2024-06-01 10:29:43\n",
      "2024-06-01 10:29:43\n",
      "Detected Symptom on cpu_r of machine-1-1\n",
      "2024-06-01 13:11:43\n",
      "2024-06-01 13:11:43\n",
      "Detected Symptom on disk_r of machine-1-1\n",
      "2024-06-01 13:55:43\n",
      "2024-06-01 13:55:43\n",
      "Detected Symptom on cpu_r of machine-1-1\n",
      "2024-06-01 13:59:43\n",
      "2024-06-01 14:01:43\n",
      "Detected Symptom on eth1_po of machine-1-1\n",
      "2024-06-01 13:59:43\n",
      "2024-06-01 13:59:43\n",
      "Detected Symptom on listen_overflows of machine-1-1\n",
      "2024-06-01 13:59:43\n",
      "2024-06-01 15:27:43\n",
      "Detected Symptom on udp_rcv_buf_errs of machine-1-1\n",
      "2024-06-01 13:59:43\n",
      "2024-06-01 13:59:43\n",
      "Detected Symptom on udp_snd_buf_errs of machine-1-1\n",
      "2024-06-01 13:59:43\n",
      "2024-06-01 15:27:43\n",
      "Detected Symptom on cpu_r of machine-1-1\n",
      "2024-06-01 14:03:43\n",
      "2024-06-01 14:07:43\n",
      "Detected Symptom on eth1_po of machine-1-1\n",
      "2024-06-01 14:03:43\n",
      "2024-06-01 14:50:43\n",
      "Detected Symptom on udp_rcv_buf_errs of machine-1-1\n",
      "2024-06-01 14:03:43\n",
      "2024-06-01 15:15:43\n",
      "Detected Symptom on disk_u of machine-1-1\n",
      "2024-06-01 14:09:43\n",
      "2024-06-01 15:28:43\n",
      "Detected Symptom on udp_in_dg of machine-1-1\n",
      "2024-06-01 14:09:43\n",
      "2024-06-01 15:24:43\n",
      "Detected Symptom on udp_out_dg of machine-1-1\n",
      "2024-06-01 14:09:43\n",
      "2024-06-01 15:24:43\n",
      "Detected Symptom on load_15 of machine-1-1\n",
      "2024-06-01 14:17:43\n",
      "2024-06-01 14:17:43\n",
      "Detected Symptom on load_15 of machine-1-1\n",
      "2024-06-01 14:20:43\n",
      "2024-06-01 14:20:43\n",
      "Detected Symptom on load_15 of machine-1-1\n",
      "2024-06-01 14:22:43\n",
      "2024-06-01 14:22:43\n",
      "Detected Symptom on load_15 of machine-1-1\n",
      "2024-06-01 14:30:43\n",
      "2024-06-01 14:32:43\n",
      "Detected Symptom on disk_r of machine-1-1\n",
      "2024-06-01 14:31:43\n",
      "2024-06-01 14:32:43\n",
      "Detected Symptom on load_15 of machine-1-1\n",
      "2024-06-01 14:36:43\n",
      "2024-06-01 14:37:43\n",
      "Detected Symptom on disk_r of machine-1-1\n",
      "2024-06-01 14:36:43\n",
      "2024-06-01 14:37:43\n",
      "Detected Symptom on cpu_r of machine-1-1\n",
      "2024-06-01 14:39:43\n",
      "2024-06-01 14:41:43\n",
      "Detected Symptom on disk_wa of machine-1-1\n",
      "2024-06-01 14:40:43\n",
      "2024-06-01 14:40:43\n",
      "Detected Symptom on disk_wb of machine-1-1\n",
      "2024-06-01 14:40:43\n",
      "2024-06-01 14:40:43\n",
      "Detected Symptom on si of machine-1-1\n",
      "2024-06-01 14:40:43\n",
      "2024-06-01 14:40:43\n",
      "Detected Symptom on curr_estab of machine-1-1\n",
      "2024-06-01 14:40:43\n",
      "2024-06-01 14:41:43\n",
      "Detected Symptom on tcp_timeouts of machine-1-1\n",
      "2024-06-01 14:40:43\n",
      "2024-06-01 14:40:43\n",
      "Detected Symptom on eth1_fo of machine-1-1\n",
      "2024-06-01 14:51:43\n",
      "2024-06-01 14:51:43\n",
      "Detected Symptom on eth1_fo of machine-1-1\n",
      "2024-06-01 14:53:43\n",
      "2024-06-01 14:53:43\n",
      "Detected Symptom on eth1_po of machine-1-1\n",
      "2024-06-01 14:54:43\n",
      "2024-06-01 14:55:43\n",
      "Detected Symptom on eth1_fo of machine-1-1\n",
      "2024-06-01 14:55:43\n",
      "2024-06-01 14:56:43\n",
      "Detected Symptom on eth1_fo of machine-1-1\n",
      "2024-06-01 15:02:43\n",
      "2024-06-01 15:11:43\n",
      "Detected Symptom on eth1_po of machine-1-1\n",
      "2024-06-01 15:06:43\n",
      "2024-06-01 15:06:43\n",
      "Detected Symptom on eth1_fo of machine-1-1\n",
      "2024-06-01 15:13:43\n",
      "2024-06-01 15:16:43\n",
      "Detected Symptom on eth1_po of machine-1-1\n",
      "2024-06-01 15:14:43\n",
      "2024-06-01 15:14:43\n",
      "Detected Symptom on udp_rcv_buf_errs of machine-1-1\n",
      "2024-06-01 15:22:43\n",
      "2024-06-01 15:26:43\n",
      "Detected Symptom on eth1_po of machine-1-1\n",
      "2024-06-01 15:25:43\n",
      "2024-06-01 15:25:43\n",
      "Detected Symptom on eth1_fo of machine-1-1\n",
      "2024-06-01 15:27:43\n",
      "2024-06-01 15:37:43\n",
      "Detected Symptom on udp_in_dg of machine-1-1\n",
      "2024-06-01 15:47:43\n",
      "2024-06-01 16:11:43\n",
      "Detected Symptom on udp_out_dg of machine-1-1\n",
      "2024-06-01 15:47:43\n",
      "2024-06-01 16:11:43\n",
      "Detected Symptom on disk_u of machine-1-1\n",
      "2024-06-01 15:51:43\n",
      "2024-06-01 16:14:43\n",
      "Detected Symptom on udp_snd_buf_errs of machine-1-1\n",
      "2024-06-01 15:58:43\n",
      "2024-06-01 15:58:43\n",
      "Detected Symptom on udp_snd_buf_errs of machine-1-1\n",
      "2024-06-01 16:00:43\n",
      "2024-06-01 16:03:43\n",
      "Detected Symptom on udp_snd_buf_errs of machine-1-1\n",
      "2024-06-01 16:11:43\n",
      "2024-06-01 16:11:43\n",
      "Detected Symptom on disk_u of machine-1-1\n",
      "2024-06-01 16:20:43\n",
      "2024-06-01 16:20:43\n",
      "Detected Symptom on disk_u of machine-1-1\n",
      "2024-06-01 16:22:43\n",
      "2024-06-01 16:23:43\n",
      "Detected Symptom on cpu_r of machine-1-1\n",
      "2024-06-01 16:45:43\n",
      "2024-06-01 16:45:43\n",
      "Detected Symptom on disk_u of machine-1-1\n",
      "2024-06-01 16:45:43\n",
      "2024-06-01 16:46:43\n",
      "Detected Symptom on cpu_r of machine-1-1\n",
      "2024-06-01 16:48:43\n",
      "2024-06-01 16:48:43\n",
      "Detected Symptom on disk_u of machine-1-1\n",
      "2024-06-01 16:48:43\n",
      "2024-06-01 16:49:43\n",
      "Detected Symptom on udp_snd_buf_errs of machine-1-1\n",
      "2024-06-01 16:48:43\n",
      "2024-06-01 16:48:43\n",
      "Detected Symptom on mem_shmem of machine-1-1\n",
      "2024-06-02 04:26:43\n",
      "2024-06-02 04:26:43\n"
     ]
    }
   ],
   "source": [
    "for network_incident in network_incidents:\n",
    "    for symptom in network_incident[2]:\n",
    "        print(f\"Detected Symptom on {db.get_metric_names()[symptom[0]]} of {machine_id}\")\n",
    "        print(datetime.datetime.fromtimestamp(symptom[1]))\n",
    "        print(datetime.datetime.fromtimestamp(symptom[2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
