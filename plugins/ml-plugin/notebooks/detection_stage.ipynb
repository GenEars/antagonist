{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Antagonist to train a symptom detection model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reproducibility\n",
    "\n",
    "Set seeds to ensure reproducible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "# Python\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "# Numpy\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset preparation\n",
    "\n",
    "Note: the dataset needs to be downloaded using the script `download_SMD_dataset.sh` in the `scripts/antagonist-ml` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from utils import SMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = r\"..\\..\\..\\data\"\n",
    "db = SMD(dataset_folder=os.path.join(data_folder,'ServerMachineDataset'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading both training and test data\n",
    "group = \"Group 1\"\n",
    "dataframes_train, _ = db.read_dataset(group_name=group, train=True, retrieve_labels=True)\n",
    "dataframes, files = db.read_dataset(group_name=group, train=False, retrieve_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a subserice given the group (machin-1-1.txt)\n",
    "service_idx = 0\n",
    "df,service_id = dataframes[service_idx], files[service_idx][:-4]\n",
    "df,labels = df[df.columns[:-2].tolist()+['timestamp']], df[['label']]\n",
    "df_train = dataframes_train[service_idx]\n",
    "df_train = df_train[df_train.columns[:-1].tolist()+['timestamp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get interpretation labels (symptoms)\n",
    "network_incidents = db.get_interpretation_labels(service_id+'.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ML Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "from ml_ad import AENetworkAnomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter up to current day to simulate the predition on the next one\n",
    "current_day = datetime.datetime(2020, 1, 13)\n",
    "next_day = current_day + datetime.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models folder\n",
    "models_folder = os.path.join(data_folder,'models')\n",
    "os.makedirs(models_folder,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'ae_model_{(current_day).strftime(\"%Y%m%d\")}'\n",
    "model_folder = os.path.join(models_folder, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(model_folder):\n",
    "    # Load the model if it exist\n",
    "    ml_model = AENetworkAnomaly.load(model_folder)\n",
    "else:\n",
    "    # Create new model \n",
    "    ml_model = AENetworkAnomaly(n_inputs=df.shape[1]-1)\n",
    "\n",
    "    # Get data up to current day (training set)\n",
    "    df_today = df.loc[df[\"timestamp\"] < current_day.ctime()]\n",
    "\n",
    "    mask_train = labels[: df_today.shape[0]][\"label\"] == 0\n",
    "    df_today = pd.concat([df_train, df_today[mask_train]], ignore_index=True)\n",
    "\n",
    "    # Train the model\n",
    "    X_train = df_today.drop('timestamp',axis=1).values\n",
    "    ml_model.fit(X_train)\n",
    "\n",
    "    # Cache the trained model\n",
    "    ml_model.store(model_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use model for detection\n",
    "\n",
    "Predict anomalies on the current day data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df.loc[\n",
    "    (df[\"timestamp\"] >= current_day.ctime())\n",
    "    & (df[\"timestamp\"] < next_day.ctime())\n",
    "]\n",
    "\n",
    "X_pred = df_pred.drop('timestamp',axis=1).values\n",
    "y_pred = ml_model.predict(X_pred, aggregate=False)\n",
    "model_predictions = ml_model.parse_predictions(df_pred, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to objects\n",
    "\n",
    "In the following code overlapping symptoms are aggregated into incidents. The code iterates over the sorted list of symptoms and groups them into incidents based on their overlapping time ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate overlapping symptoms coming from different metrics\n",
    "day_symptoms = [\n",
    "    (metric_id, symptom[0], symptom[1]) for metric_id, symptoms_list in model_predictions.items() for symptom in symptoms_list \n",
    "]\n",
    "\n",
    "# sort by starting timestamp\n",
    "day_symptoms.sort(key=lambda x: x[1])\n",
    "\n",
    "if len(day_symptoms) > 0:\n",
    "    # create a list of incident in the form [(start_timestamp, end_timestamp, [symptom1, symptom2]),...]\n",
    "    start = day_symptoms[0][1] \n",
    "    end = day_symptoms[0][2]\n",
    "    network_incidents = [[start, end, [day_symptoms[0]]]]\n",
    "    for symptom in day_symptoms[1:]:\n",
    "        # if overlapping add to the current incident, new incident otherwise\n",
    "        if symptom[1] <= end:\n",
    "            network_incidents[-1][2].append(symptom)\n",
    "            end = max(end, symptom[2])\n",
    "            network_incidents[-1][1] = end\n",
    "        else:\n",
    "            start = symptom[1]\n",
    "            end = symptom[2]\n",
    "            network_incidents.append([start, end, [symptom]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store into antagonist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the antagonist_ml methods\n",
    "import sys \n",
    "sys.path.append(\"..\")\n",
    "from antagonist_ml.service import store_network_anomalies_labels, store_network_symptom_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for network_incident in network_incidents:\n",
    "\n",
    "    # Create network incident label\n",
    "    ni_uuid = store_network_anomalies_labels(\n",
    "        antagonist_host='localhost:5001',\n",
    "        author_name=model_name,\n",
    "        author_type=\"algorithm\",\n",
    "        author_version=1,\n",
    "        description=f'Detected Network Anomaly on {service_id} - {datetime.datetime.fromtimestamp(network_incident[0]).strftime(\"%Y-%m-%d at %H\")}',\n",
    "        state=\"incident-potential\",\n",
    "        version=1,\n",
    "    )\n",
    "\n",
    "    # Create network symptoms labels and link with the network incident\n",
    "    for symptom in network_incident[2]:\n",
    "        store_network_symptom_labels(    \n",
    "            antagonist_host='localhost:5001',\n",
    "            author_name=model_name,\n",
    "            author_type=\"algorithm\",\n",
    "            author_version=1,\n",
    "            confidence=1.0,\n",
    "            concern_score=0.9,\n",
    "            description=f\"Detected Symptom on {db.get_metric_names()[symptom[0]]} of {service_id}\",\n",
    "            start=symptom[1],\n",
    "            end=symptom[2],\n",
    "            version=1,\n",
    "            tags={\"machine\": service_id, \"metric\": db.get_metric_names()[symptom[0]], \"group\": group},\n",
    "            network_anomaly_uuid=ni_uuid,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
